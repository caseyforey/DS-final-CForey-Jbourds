{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tournaments.ipynb\n",
    "\n",
    "Jupyter Notebook to perform analysis on card market data.\n",
    "\n",
    "Author: Casey Forey\n",
    "Date Created: 4/7/24\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Imports\n",
    "from importlib import reload\n",
    "import json \n",
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import src.constants as c\n",
    "import src.load.load_set_data as lsd\n",
    "import src.load.load_tournament_data as ltd\n",
    "import src.plot.plot_set_data as psd\n",
    "import src.plot.plot_tournament_data as ptd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/AtomicCards.json' \n",
    "f = open(path, encoding= \"utf8\") \n",
    "atm_cards = json.load(f)\n",
    "\n",
    "path = 'data/AllPrintings.json' \n",
    "f = open(path, encoding= \"utf8\") \n",
    "all_cards = json.load(f)\n",
    "\n",
    "path = 'data/AllPricesToday.json' \n",
    "f = open(path) \n",
    "prices = json.load(f)\n",
    "\n",
    "path = 'data/SetList.json' \n",
    "f = open(path, encoding= \"utf8\") \n",
    "set_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path: str = os.path.join(c.DATA_DIRECTORY, '2023')\n",
    "modern_card_counts_df, player_counts_df = ltd.load_format_card_counts(base_path, 'modern')\n",
    "modern_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = atm_cards['data']\n",
    "cards_set = {}\n",
    "i = 0\n",
    "for card in data:\n",
    "    card_info = data[card][0]\n",
    "    if 'firstPrinting' in card_info:\n",
    "        cards_set[card] = card_info['firstPrinting']\n",
    "    else:\n",
    "        i +=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_set_df = pd.DataFrame.from_dict(cards_set, orient='index')\n",
    "cards_set_df.reset_index(inplace= True) \n",
    "cards_set_df.rename(columns={'index': 'card_name', 0: 'set_code'},inplace= True) \n",
    "cards_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_back_face(df):\n",
    "    for card in df['card_name']:\n",
    "        for name in cards_set_df['card_name']:\n",
    "            front_name = name.split('//')[0].strip()\n",
    "            if card == front_name and '//' in name:\n",
    "                df['card_name'].replace(card, name,inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_card_counts_df = add_back_face(modern_card_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if double face cards look correct\n",
    "for name in modern_card_counts_df['card_name']:\n",
    "    if \"Smelt\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_card_counts_df[modern_card_counts_df['card_name'] == 'Smelt // Herd // Saw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_card_counts_df = modern_card_counts_df.merge(cards_set_df, on = 'card_name', how = 'left')\n",
    "modern_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(lsd)\n",
    "\n",
    "set_release_df: pd.DataFrame = lsd.get_set_and_release_year()\n",
    "set_release_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_card_counts_df = modern_card_counts_df.merge(set_release_df, on='set_code', how='left', copy=True)\n",
    "modern_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(psd)\n",
    "%matplotlib inline\n",
    "\n",
    "augmented_modern_card_counts_df: pd.DataFrame = lsd.load_augmented_set_data(all_cards, 'modern')\n",
    "\n",
    "legend_params: list[tuple] = [\n",
    "    (2011, 'orange', '--', 'Start of Modern Format (2011)'),\n",
    "    (2019, 'red', '--', 'Fire Design Principle Implemented (2019)'),\n",
    "    (2021, 'blue', '--', 'Modern Horizons 2 Released (2021)'),\n",
    "]\n",
    "psd.plot_stacked_set_counts(augmented_modern_card_counts_df, set_release_df, 'modern', True, legend_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very limited Graph as a proof of concept\n",
    "modern_card_counts_df.groupby('release_year')['total_count'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(ptd)\n",
    "\n",
    "# ptd.plot_card_counts(modern_card_counts_df,(255/255,122/255,14/255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pioneer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path: str = os.path.join(c.DATA_DIRECTORY, '2023')\n",
    "pioneer_card_counts_df, pioneer_player_counts_df = ltd.load_format_card_counts(base_path, 'pioneer')\n",
    "pioneer_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pioneer_card_counts_df = add_back_face(pioneer_card_counts_df)\n",
    "pioneer_card_counts_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in pioneer_card_counts_df['card_name']:\n",
    "    if \"Fable\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pioneer_card_counts_df = pioneer_card_counts_df.merge(cards_set_df, on = 'card_name', how = 'left')\n",
    "pioneer_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pioneer_card_counts_df = pioneer_card_counts_df.merge(set_release_df, on = 'set_code', how = 'left', copy = True)\n",
    "pioneer_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make set banned cards array and save it as a Numpy array\n",
    "\n",
    "pioneer_banned_cards: str = \"\"\"Balustrade Spy\n",
    "Bloodstained Mire\n",
    "Expressive Iteration\n",
    "Felidar Guardian\n",
    "Field of the Dead\n",
    "Flooded Strand\n",
    "Geological Appraiser\n",
    "Inverter of Truth\n",
    "Karn, the Great Creator\n",
    "Kethis, the Hidden Hand\n",
    "Leyline of Abundance\n",
    "Lurrus of the Dream-Den\n",
    "Nexus of Fate\n",
    "Oko, Thief of Crowns\n",
    "Once Upon a Time\n",
    "Polluted Delta\n",
    "Teferi, Time Raveler\n",
    "Undercity Informer\n",
    "Underworld Breach\n",
    "Uro, Titan of Nature's Wrath\n",
    "Veil of Summer\n",
    "Walking Ballista\n",
    "Wilderness Reclamation\n",
    "Windswept Heath\n",
    "Winota, Joiner of Forces\n",
    "Wooded Foothills\n",
    "\"\"\"\n",
    "pioneer_banned_cards: np.array = np.array(pioneer_banned_cards.split('\\n'))\n",
    "np.save(os.path.join(c.DATA_DIRECTORY, c.CACHE, 'pioneer_banned_cards'), pioneer_banned_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make set legal sets dataframe and save it as a csv\n",
    "\n",
    "pioneer_legal_sets: str = \"\"\"Return to Ravnica\n",
    "Gatecrash\n",
    "Dragon's Maze\n",
    "Magic 2014\n",
    "Theros\n",
    "Born of the Gods\n",
    "Journey into Nyx\n",
    "Magic 2015\n",
    "Khans of Tarkir\n",
    "Fate Reforged\n",
    "Dragons of Tarkir\n",
    "Magic Origins\n",
    "Battle for Zendikar\n",
    "Oath of the Gatewatch\n",
    "Welcome Deck 2016\n",
    "Shadows over Innistrad\n",
    "Eldritch Moon\n",
    "Kaladesh\n",
    "Aether Revolt\n",
    "Welcome Deck 2017\n",
    "Amonkhet\n",
    "Hour of Devastation\n",
    "Ixalan\n",
    "Rivals of Ixalan\n",
    "Dominaria\n",
    "Core Set 2019\n",
    "Guilds of Ravnica\n",
    "Ravnica Allegiance\n",
    "War of the Spark\n",
    "Core Set 2020\n",
    "Throne of Eldraine\n",
    "Theros Beyond Death\n",
    "Ikoria: Lair of Behemoths\n",
    "Core Set 2021\n",
    "Zendikar Rising\n",
    "Kaldheim\n",
    "Strixhaven: School of Mages\n",
    "Adventures in the Forgotten Realms\n",
    "Innistrad: Midnight Hunt\n",
    "Innistrad: Crimson Vow\n",
    "Kamigawa: Neon Dynasty\n",
    "Streets of New Capenna\n",
    "Dominaria United\n",
    "The Brothers' War\n",
    "Phyrexia: All Will Be One\n",
    "March of the Machine\n",
    "March of the Machine: The Aftermath\n",
    "Wilds of Eldraine\n",
    "The Lost Caverns of Ixalan\n",
    "Murders at Karlov Manor\n",
    "\"\"\"\n",
    "pioneer_legal_sets: pd.DataFrame = pd.DataFrame({'set_name': pioneer_legal_sets.split('\\n')})\n",
    "pioneer_legal_sets = pioneer_legal_sets.merge(set_release_df, on='set_name')\n",
    "pioneer_legal_sets.to_csv(os.path.join(c.DATA_DIRECTORY, c.CACHE, 'pioneer_legal_sets.csv'), index=False)\n",
    "pioneer_legal_sets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make set ban counts dataframe and save it as a csv\n",
    "pioneer_banned_cards_df: pd.DataFrame = pd.DataFrame({'card_name': pioneer_banned_cards}).merge(cards_set_df, on='card_name')\n",
    "\n",
    "pioneer_grouped_set_bancount: pd.DataFrame = pioneer_banned_cards_df.groupby(['set_code']).size().reset_index().rename(columns={0: 'num_banned'})\n",
    "pioneer_final_set_bancount: pd.DataFrame = pioneer_legal_sets.merge(pioneer_grouped_set_bancount, on='set_code', how='left').fillna(0)\n",
    "pioneer_final_set_bancount.to_csv(os.path.join(c.DATA_DIRECTORY, c.CACHE, 'pioneer_set_ban_counts.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(psd)\n",
    "%matplotlib inline\n",
    "\n",
    "augmented_pioneer_card_counts_df: pd.DataFrame = lsd.load_augmented_set_data(all_cards, 'pioneer')\n",
    "\n",
    "legend_params: list[tuple] = [\n",
    "    (2019, 'red', '--', 'Fire Design Principle Implemented (2019)'),\n",
    "    (2019, 'blue', ':', 'Pioneer Format Starts (2019)'),\n",
    "]\n",
    "psd.plot_stacked_set_counts(augmented_pioneer_card_counts_df, set_release_df, 'pioneer', True, legend_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(ptd)\n",
    "\n",
    "# ptd.plot_card_counts(pioneer_card_counts_df, (9/255, 121/255, 105/255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path: str = os.path.join(c.DATA_DIRECTORY, '2023')\n",
    "legacy_card_counts_df, legacy_player_counts_df = ltd.load_format_card_counts(base_path, 'legacy')\n",
    "legacy_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_card_counts_df = add_back_face(legacy_card_counts_df)\n",
    "legacy_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in legacy_card_counts_df['card_name']:\n",
    "    if \"Fable\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_card_counts_df = legacy_card_counts_df.merge(cards_set_df, on = 'card_name', how = 'left')\n",
    "legacy_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_card_counts_df = legacy_card_counts_df.merge(set_release_df, on = 'set_code', how = 'left', copy = True)\n",
    "legacy_card_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make set banned cards array and save it as a Numpy array\n",
    "\n",
    "legacy_banned_cards: str = \"\"\"Ancestral Recall\n",
    "Arcum's Astrolabe\n",
    "Balance\n",
    "Bazaar of Baghdad\n",
    "Black Lotus\n",
    "Channel\n",
    "Demonic Consultation\n",
    "Deathrite Shaman\n",
    "Demonic Tutor\n",
    "Dig Through Time\n",
    "Dreadhorde Arcanist\n",
    "Earthcraft\n",
    "Expressive Iteration\n",
    "Fastbond\n",
    "Flash\n",
    "Frantic Search\n",
    "Gitaxian Probe\n",
    "Goblin Recruiter\n",
    "Gush\n",
    "Hermit Druid\n",
    "Imperial Seal\n",
    "Library of Alexandria\n",
    "Lurrus of the Dream-Den\n",
    "Mana Crypt\n",
    "Mana Drain\n",
    "Mana Vault\n",
    "Memory Jar\n",
    "Mental Misstep\n",
    "Mind Twist\n",
    "Mishra's Workshop\n",
    "Mox Emerald\n",
    "Mox Jet\n",
    "Mox Pearl\n",
    "Mox Ruby\n",
    "Mox Sapphire\n",
    "Mystical Tutor\n",
    "Necropotence\n",
    "Oath of Druids\n",
    "Oko, Thief of Crowns\n",
    "Ragavan, Nimble Pilferer\n",
    "Sensei's Divining Top\n",
    "Skullclamp\n",
    "Sol Ring\n",
    "Strip Mine\n",
    "Survival of the Fittest\n",
    "Time Vault\n",
    "Time Walk\n",
    "Timetwister\n",
    "Tinker\n",
    "Tolarian Academy\n",
    "Treasure Cruise\n",
    "Underworld Breach\n",
    "Vampiric Tutor\n",
    "Wheel of Fortune\n",
    "White Plume Adventurer\n",
    "Windfall\n",
    "Wrenn and Six\n",
    "Yawgmoth's Bargain\n",
    "Yawgmoth's Will\n",
    "Zirda, the Dawnwaker\n",
    "\"\"\"\n",
    "legacy_banned_cards: np.array = np.array(legacy_banned_cards.split('\\n'))\n",
    "np.save(os.path.join(c.DATA_DIRECTORY, c.CACHE, 'legacy_banned_cards'), legacy_banned_cards)\n",
    "\n",
    "# Make set legal sets dataframe and save it as a csv\n",
    "\n",
    "legacy_legal_sets: str = [set_entry['name'] for set_entry in set_list['data']]\n",
    "legacy_legal_sets: pd.DataFrame = pd.DataFrame({'set_name': legacy_legal_sets})\n",
    "legacy_legal_sets = legacy_legal_sets.merge(set_release_df, on='set_name')\n",
    "legacy_legal_sets.to_csv(os.path.join(c.DATA_DIRECTORY, c.CACHE, 'legacy_legal_sets.csv'), index=False)\n",
    "legacy_legal_sets.head()\n",
    "\n",
    "# Make set ban counts dataframe and save it as a csv\n",
    "legacy_banned_cards_df: pd.DataFrame = pd.DataFrame({'card_name': legacy_banned_cards}).merge(cards_set_df, on='card_name')\n",
    "\n",
    "legacy_grouped_set_bancount: pd.DataFrame = legacy_banned_cards_df.groupby(['set_code']).size().reset_index().rename(columns={0: 'num_banned'})\n",
    "legacy_final_set_bancount: pd.DataFrame = legacy_legal_sets.merge(legacy_grouped_set_bancount, on='set_code', how='left').fillna(0)\n",
    "legacy_final_set_bancount.to_csv(os.path.join(c.DATA_DIRECTORY, c.CACHE, 'legacy_set_ban_counts.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(psd)\n",
    "%matplotlib inline\n",
    "\n",
    "augmented_legacy_card_counts_df: pd.DataFrame = lsd.load_augmented_set_data(all_cards, 'legacy')\n",
    "\n",
    "legend_params: list[tuple] = [\n",
    "    (1997, 'blue', ':', 'Legacy Format Starts (1997)'),\n",
    "    (2019, 'red', '--', 'Fire Design Principle Implemented (2019)'),\n",
    "]\n",
    "psd.plot_stacked_set_counts(augmented_legacy_card_counts_df, set_release_df, 'legacy', True, legend_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(ptd)\n",
    "\n",
    "# ptd.plot_card_counts(legacy_card_counts_df, (255/255, 215/255, 0/255))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
